{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Stage 1\n",
      "Stage 1: Dropping arm LLM_1 due to low scores\n",
      "Stage 1: Dropping arm LLM_2 due to low scores\n",
      "Stage 1: Dropping arm LLM_3 due to low scores\n",
      "Running Stage 2\n",
      "Running Stage 3\n",
      "Running Stage 4\n",
      "Running Stage 5\n",
      "\n",
      "Final Results:\n",
      "          Knowledge   Empathy  Usefulness\n",
      "Arm                                      \n",
      "Expert_1   3.892595  3.998176    3.917999\n",
      "Expert_2   4.158458  4.060552    4.114116\n",
      "LLM_1      3.314113  3.492615    3.500321\n",
      "LLM_2      3.195856  3.142112    3.264809\n",
      "LLM_3      3.500844  3.535780    3.399151\n",
      "\n",
      "Best performing arm: Expert_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/6krmxw152qjflvfhkn0bn4r40000gn/T/ipykernel_31389/2927139466.py:54: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.data = pd.concat([self.data, pd.DataFrame(stage_data)], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "class ChatParkSimulation:\n",
    "    def __init__(self, num_llms, num_human_experts, num_stages, num_questions_per_stage):\n",
    "        self.num_llms = num_llms\n",
    "        self.num_human_experts = num_human_experts\n",
    "        self.num_arms = num_llms + num_human_experts\n",
    "        self.num_stages = num_stages\n",
    "        self.num_questions_per_stage = num_questions_per_stage\n",
    "        \n",
    "        # Initialize arms (LLMs + human experts)\n",
    "        self.arms = [f\"LLM_{i+1}\" for i in range(num_llms)] + [f\"Expert_{i+1}\" for i in range(num_human_experts)]\n",
    "        \n",
    "        # Set up data storage\n",
    "        self.data = pd.DataFrame(columns=['Stage', 'Arm', 'Question', 'Knowledge', 'Empathy', 'Usefulness'])\n",
    "        \n",
    "        # Set up arm status (active/inactive)\n",
    "        self.arm_status = {arm: True for arm in self.arms}\n",
    "        \n",
    "    def generate_question(self):\n",
    "        # In a real scenario, this would pull from a database of patient questions\n",
    "        return f\"Question about Parkinson's disease #{np.random.randint(1000)}\"\n",
    "    \n",
    "    def generate_response(self, arm):\n",
    "        # Simulate response quality based on arm type (LLM vs Expert)\n",
    "        if 'LLM' in arm:\n",
    "            base_quality = np.random.normal(3.5, 0.5)  # LLMs slightly lower base quality\n",
    "        else:\n",
    "            base_quality = np.random.normal(4, 0.5)  # Experts slightly higher base quality\n",
    "        \n",
    "        knowledge = max(1, min(5, base_quality + np.random.normal(0, 0.5)))\n",
    "        empathy = max(1, min(5, base_quality + np.random.normal(0, 0.5)))\n",
    "        usefulness = max(1, min(5, base_quality + np.random.normal(0, 0.5)))\n",
    "        \n",
    "        return knowledge, empathy, usefulness\n",
    "    \n",
    "    def run_stage(self, stage):\n",
    "        stage_data = []\n",
    "        for _ in range(self.num_questions_per_stage):\n",
    "            question = self.generate_question()\n",
    "            for arm in self.arms:\n",
    "                if self.arm_status[arm]:\n",
    "                    knowledge, empathy, usefulness = self.generate_response(arm)\n",
    "                    stage_data.append({\n",
    "                        'Stage': stage,\n",
    "                        'Arm': arm,\n",
    "                        'Question': question,\n",
    "                        'Knowledge': knowledge,\n",
    "                        'Empathy': empathy,\n",
    "                        'Usefulness': usefulness\n",
    "                    })\n",
    "        self.data = pd.concat([self.data, pd.DataFrame(stage_data)], ignore_index=True)\n",
    "    \n",
    "    def analyze_stage(self, stage):\n",
    "        stage_data = self.data[self.data['Stage'] == stage]\n",
    "        arm_means = stage_data.groupby('Arm')[['Knowledge', 'Empathy', 'Usefulness']].mean()\n",
    "        \n",
    "        # Simple decision rule: drop arms with mean score < 3.5 in any category\n",
    "        for arm in self.arms:\n",
    "            if self.arm_status[arm] and (arm_means.loc[arm] < 3.5).any():\n",
    "                self.arm_status[arm] = False\n",
    "                print(f\"Stage {stage}: Dropping arm {arm} due to low scores\")\n",
    "        \n",
    "        # Check if we should stop for efficacy (if any arm has mean score > 4.5 in all categories)\n",
    "        best_arm = arm_means[(arm_means > 4.5).all(axis=1)].index\n",
    "        if not best_arm.empty:\n",
    "            print(f\"Stage {stage}: Stopping for efficacy. Best arm: {best_arm[0]}\")\n",
    "            return True\n",
    "        \n",
    "        # Check if we should stop for futility (if all arms are inactive)\n",
    "        if not any(self.arm_status.values()):\n",
    "            print(f\"Stage {stage}: Stopping for futility. No arms remain active.\")\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def run_trial(self):\n",
    "        for stage in range(1, self.num_stages + 1):\n",
    "            print(f\"Running Stage {stage}\")\n",
    "            self.run_stage(stage)\n",
    "            if self.analyze_stage(stage):\n",
    "                break\n",
    "        \n",
    "        # Final analysis\n",
    "        final_data = self.data.groupby('Arm')[['Knowledge', 'Empathy', 'Usefulness']].mean()\n",
    "        print(\"\\nFinal Results:\")\n",
    "        print(final_data)\n",
    "        \n",
    "        best_arm = final_data.mean(axis=1).idxmax()\n",
    "        print(f\"\\nBest performing arm: {best_arm}\")\n",
    "\n",
    "# Run the simulation\n",
    "np.random.seed(42)  # for reproducibility\n",
    "sim = ChatParkSimulation(num_llms=3, num_human_experts=2, num_stages=5, num_questions_per_stage=20)\n",
    "sim.run_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmed219-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
