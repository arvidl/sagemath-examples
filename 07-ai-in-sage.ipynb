{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dedd2a6",
   "metadata": {},
   "source": [
    "# 07-ai-in-sage.ipynb\n",
    "\n",
    "\n",
    "A.L. 2023-08-21 (Ubuntu 2022.04, Sage 10.1)<br>\n",
    "A.L. 2024-07-22 (MacBook Air 11 inch, Mid 2012, MacOs 10.15.7, Sage 10.3, using `brew install llm`)<br>\n",
    "A.L. 2024-07-24 (MacBook Air 11 inch, Mid 2012, MacOs 10.15.7, Sage 10.3, using `Llama 3.1 8B`)<br>\n",
    "A.L. 2024-07-25 (MacBook Pro 16 inch, 2019, MacOs Sonoma 14.5, Sage 10.3, using `Llama 3.1 8B`)<br>\n",
    "\n",
    "\n",
    "If you've already installed LLM the following set of commands should get you setup with Llama 3.1 8B:\n",
    "```bash\n",
    "    llm install llm-gguf\n",
    "    llm gguf download-model \\\n",
    "      https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf \\\n",
    "      --alias llama-3.1-8b-instruct --alias l31i\n",
    "```\n",
    "\n",
    "This will download a 4.92GB GGUF from lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF on Hugging Face and save it (at least on macOS) to your `~/Library/Application Support/io.datasette.llm/gguf/models` folder.\n",
    "Once installed like that, you can run prompts through the model like so:\n",
    "```bash\n",
    "    llm -m l31i \"five great names for a pet lemur\"\n",
    "```\n",
    "Or use the `llm chat` command to keep the model resident in memory and run an interactive chat session with it:\n",
    "```bash\n",
    "    llm chat -m l31i\n",
    "```\n",
    "\n",
    "### Anthropic Claude 3.5 Sonnet\n",
    "\n",
    "To Get API keys:<be>\n",
    "https://console.anthropic.com/dashboard\n",
    "\n",
    "```bash\n",
    "llm install llm-claude-3\n",
    "llm keys set claude\n",
    "# <Paste key here>\n",
    "\n",
    "# Now list available models\n",
    "llm models\n",
    "# and, to include a list of their options\n",
    "llm models --options\n",
    "# Then run a prompt\n",
    "llm -m claude-3.5-sonnet 'Fun facts about pelicans'\n",
    "llm -m claude-3-haiku-20240307 'say hi in spanish with a flourish'\n",
    "```\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm models          \n",
    "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
    "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
    "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
    "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
    "OpenAI Chat: gpt-4-1106-preview\n",
    "OpenAI Chat: gpt-4-0125-preview\n",
    "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
    "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
    "OpenAI Chat: gpt-4o (aliases: 4o)\n",
    "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
    "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
    "Anthropic Messages: claude-3-opus-20240229 (aliases: claude-3-opus)\n",
    "Anthropic Messages: claude-3-sonnet-20240229 (aliases: claude-3-sonnet)\n",
    "Anthropic Messages: claude-3-haiku-20240307 (aliases: claude-3-haiku)\n",
    "Anthropic Messages: claude-3-5-sonnet-20240620 (aliases: claude-3.5-sonnet)\n",
    "GgufChatModel: gguf/Meta-Llama-3.1-8B-Instruct-Q4_K_M (aliases: llama-3.1-8b-instruct, l31i)\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```\n",
    " \n",
    "\n",
    "### jupyter-ai\n",
    "\n",
    "- https://github.com/jupyterlab/jupyter-ai\n",
    "\n",
    "- https://openai.com/api/\n",
    "\n",
    "You can find your API key at https://platform.openai.com/account/api-keys.\n",
    "\n",
    "\n",
    "```\n",
    "echo \"export OPENAI_API_KEY='yourkey'\" >> ~/.zshrc   (or  ~/.bashrc )\n",
    "source ~/.zshrc\n",
    "echo $OPENAI_API_KEY\n",
    "```\n",
    "or\n",
    "```\n",
    "import os\n",
    "import openai\n",
    " \n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "```\n",
    "\n",
    "\n",
    "See also: https://sagemanifolds.obspm.fr/install_ubuntu.html\n",
    "\n",
    "Check sage installation and start a Jupyter notebook with the SageMath 9.6 kernel:\n",
    "\n",
    "```\n",
    "sage -c 'print(version())\n",
    "sage -notebook\n",
    "```\n",
    "\n",
    "\n",
    "Installing R-packages:\n",
    "```\n",
    "sage -R\n",
    "\n",
    "> install.packages(\"lme4\")\n",
    "```\n",
    "\n",
    "Installing Python packages (in the sage kernel):\n",
    "```\n",
    "> sage --pip install pandas\n",
    "> sage --pip install seaborn\n",
    "> sage --pip install networkx\n",
    "> sage --pip install igraph\n",
    "> # sage --pip install pycairo\n",
    "> # sage --pip install cairocffi\n",
    "> # sage --pip install leidenalg\n",
    "> sage --pip install jupyterlab\n",
    "> sage --pip install altair vega_datasets      # https://altair-viz.github.io/index.html\n",
    "> sage --pip install pygraphviz\n",
    "\n",
    "> sage --pip install openai\n",
    "> sage --pip install jupyter_ai\n",
    "> sage --pip install python-dotenv\n",
    "```\n",
    "\n",
    "```\n",
    "%reload_ext jupyter_ai\n",
    "\n",
    "%%ai chatgpt --format code\n",
    "A function that computes the lowest common multiples of two integers, and a function that runs 5 test cases of the lowest common multiple function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c30bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211036a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] MODEL_ID\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  -m, --model-parameters TEXT     A JSON value that specifies extra values\n",
      "                                  that will be passed to the model. The\n",
      "                                  accepted value parsed to a dict, unpacked\n",
      "                                  and passed as-is to the provider class.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f490af14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">‚ùå</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:anthropic.claude-v1`</li><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li></ul> |\n",
       "| `anthropic` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">‚ùå</abbr> | <ul><li>`anthropic:claude-v1`</li><li>`anthropic:claude-v1.0`</li><li>`anthropic:claude-v1.2`</li><li>`anthropic:claude-2`</li><li>`anthropic:claude-2.0`</li><li>`anthropic:claude-instant-v1`</li><li>`anthropic:claude-instant-v1.0`</li><li>`anthropic:claude-instant-v1.2`</li></ul> |\n",
       "| `anthropic-chat` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">‚ùå</abbr> | <ul><li>`anthropic-chat:claude-v1`</li><li>`anthropic-chat:claude-v1.0`</li><li>`anthropic-chat:claude-v1.2`</li><li>`anthropic-chat:claude-2`</li><li>`anthropic-chat:claude-2.0`</li><li>`anthropic-chat:claude-instant-v1`</li><li>`anthropic-chat:claude-instant-v1.0`</li><li>`anthropic-chat:claude-instant-v1.2`</li></ul> |\n",
       "| `azure-chat-openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">‚úÖ</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">‚ùå</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">‚ùå</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">‚úÖ</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">‚úÖ</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-0301`</li><li>`openai-chat:gpt-3.5-turbo-0613`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-3.5-turbo-16k`</li><li>`openai-chat:gpt-3.5-turbo-16k-0613`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-32k`</li><li>`openai-chat:gpt-4-32k-0613`</li><li>`openai-chat:gpt-4-1106-preview`</li></ul> |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">‚ùå</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n"
      ],
      "text/plain": [
       "<jupyter_ai_magics.magics.TextOrMarkdown object at 0x16ff54750>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201a507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">‚úÖ</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n"
      ],
      "text/plain": [
       "<jupyter_ai_magics.magics.TextOrMarkdown object at 0x16ff644d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a18544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \n",
       "\\frac{\\partial u}{\\partial t} = \\alpha \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right)\n",
       "$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/latex": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f math\n",
    "Generate the 2D heat equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958e0b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt --format code\n",
    "A function that computes the lowest common multiples of two integers, and a function that runs 5 test cases of the lowest common multiple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b565bf8-0663-4c9c-9d2d-69b11f5be20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcm(a, b):\n",
    "    def gcd(a, b):\n",
    "        while b:\n",
    "            a, b = b, a % b\n",
    "        return a\n",
    "    return abs(a*b) // gcd(a, b)\n",
    "\n",
    "def test_lcm():\n",
    "    test_cases = [(3, 5), (10, 15), (7, 9), (18, 24), (30, 40)]\n",
    "    \n",
    "    for a, b in test_cases:\n",
    "        print(f\"LCM of {a} and {b} is: {lcm(a, b)}\")\n",
    "\n",
    "test_lcm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5224b3-0633-4177-a58d-e9cf03da2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcm(a, b):\n",
    "    if a == 0 or b == 0:\n",
    "        return 0\n",
    "    max_num = max(a, b)\n",
    "    while True:\n",
    "        if max_num % a == 0 and max_num % b == 0:\n",
    "            return max_num\n",
    "        max_num += 1\n",
    "\n",
    "def test_lcm():\n",
    "    test_cases = [(3, 5), (10, 15), (7, 9), (20, 25), (18, 24)]\n",
    "    for a, b in test_cases:\n",
    "        result = lcm(a, b)\n",
    "        print(f\"LCM of {a} and {b} is {result}\")\n",
    "\n",
    "test_lcm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55989eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCM of 3 and 5 is 15\n",
      "LCM of 9 and 12 is 36\n",
      "LCM of 8 and 14 is 56\n",
      "LCM of 15 and 20 is 60\n",
      "LCM of 24 and 36 is 72\n",
      "LCM of 9 and 28 is 252\n"
     ]
    }
   ],
   "source": [
    "def lcm(a, b):\n",
    "    # Find the maximum of a and b\n",
    "    if a > b:\n",
    "        max_num = a\n",
    "    else:\n",
    "        max_num = b\n",
    "\n",
    "    # Iterate and find the lowest common multiple\n",
    "    while True:\n",
    "        if max_num % a == 0 and max_num % b == 0:\n",
    "            return max_num\n",
    "        max_num += 1\n",
    "\n",
    "def run_lcm_tests():\n",
    "    # Run test cases\n",
    "    test_cases = [(3, 5), (9, 12), (8, 14), (15, 20), (24, 36), (9,28)]\n",
    "    \n",
    "    for a, b in test_cases:\n",
    "        result = lcm(a, b)\n",
    "        print(f\"LCM of {a} and {b} is {result}\")\n",
    "\n",
    "# Run the test cases\n",
    "run_lcm_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d495c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "poet = \"Herman Wildenvvey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52b6dee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Vindens Sang\n",
       "\n",
       "I skogen h√∏rer jeg vinden synge,\n",
       "En melodi s√• vakker og ren,\n",
       "Gjennom tr√¶rne den sakte svinge,\n",
       "Og min sjel den fanger med en gang.\n",
       "\n",
       "Naturens symfoni av sus og brus,\n",
       "Fyller mitt hjerte med glede og ro,\n",
       "Som en elv av toner som aldri tar slutt,\n",
       "En evighet av fred og harmoni.\n",
       "\n",
       "S√• la meg bli ett med denne sang,\n",
       "La meg f√∏le vinden i mitt indre,\n",
       "For i naturen finner jeg min trang,\n",
       "Til √• v√¶re fri og leve uten hindre."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt \n",
    "Write a poem in the style of {poet} in Norwegian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247ddeb",
   "metadata": {},
   "source": [
    "## llm   Simon Willison\n",
    "\n",
    "https://github.com/simonw/llm\n",
    "\n",
    "https://llm.datasette.io/en/stable/usage.html\n",
    "\n",
    "```bash\n",
    "If you have an OpenAI API key you can get started using the OpenAI models right away.\n",
    "\n",
    "As an alternative to OpenAI, you can install plugins to access models by other providers, including models that can be installed and run on your own device.\n",
    "\n",
    "Save your OpenAI API key like this:\n",
    "\n",
    "llm keys set openai\n",
    "This will prompt you for your key like so:\n",
    "\n",
    "Enter key: <paste here>\n",
    "```\n",
    "\n",
    "Now that you've saved a key you can run a prompt like this:\n",
    "```bash\n",
    "llm \"Five cute names for a pet penguin\"\n",
    "```\n",
    "\n",
    "The OpenAI API key is saved in keys.json:\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % ls -l /Users/arvid/Library/Application\\ Support/io.datasette.llm\n",
    "total 136\n",
    "-rw-------  1 arvid  staff    146 Jul 20 17:47 keys.json\n",
    "-rw-r--r--  1 arvid  staff  65536 Jul 20 20:09 logs.db\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm models\n",
    "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
    "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
    "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
    "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
    "OpenAI Chat: gpt-4-1106-preview\n",
    "OpenAI Chat: gpt-4-0125-preview\n",
    "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
    "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
    "OpenAI Chat: gpt-4o (aliases: 4o)\n",
    "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
    "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
    "```\n",
    "\n",
    "To describe how the code a file works, try this:\n",
    "```bash\n",
    "cat mycode.py | llm -s \"Explain this code\"\n",
    "```\n",
    "\n",
    "Additional examples and functions:\n",
    "\n",
    "```bash\n",
    "llm 'Ten names for cheesecakes' -m gpt-4o\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm models --options\n",
    "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
    "  temperature: float\n",
    "    What sampling temperature to use, between 0 and 2. Higher values like\n",
    "    0.8 will make the output more random, while lower values like 0.2 will\n",
    "    make it more focused and deterministic.\n",
    "  max_tokens: int\n",
    "    Maximum number of tokens to generate.\n",
    "  top_p: float\n",
    "    An alternative to sampling with temperature, called nucleus sampling,\n",
    "    where the model considers the results of the tokens with top_p\n",
    "    probability mass. So 0.1 means only the tokens comprising the top 10%\n",
    "    probability mass are considered. Recommended to use top_p or\n",
    "    temperature but not both.\n",
    "  frequency_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on their existing frequency in the text so far, decreasing the model's\n",
    "    likelihood to repeat the same line verbatim.\n",
    "  presence_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on whether they appear in the text so far, increasing the model's\n",
    "    likelihood to talk about new topics.\n",
    "  stop: str\n",
    "    A string where the API will stop generating further tokens.\n",
    "  logit_bias: dict, str\n",
    "    Modify the likelihood of specified tokens appearing in the completion.\n",
    "    Pass a JSON string like '{\"1712\":-100, \"892\":-100, \"1489\":-100}'\n",
    "  seed: int\n",
    "    Integer seed to attempt to sample deterministically\n",
    "  json_object: boolean\n",
    "    Output a valid JSON object {...}. Prompt must mention JSON.\n",
    "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-1106-preview\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-0125-preview\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4o (aliases: 4o)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
    "  temperature: float\n",
    "    What sampling temperature to use, between 0 and 2. Higher values like\n",
    "    0.8 will make the output more random, while lower values like 0.2 will\n",
    "    make it more focused and deterministic.\n",
    "  max_tokens: int\n",
    "    Maximum number of tokens to generate.\n",
    "  top_p: float\n",
    "    An alternative to sampling with temperature, called nucleus sampling,\n",
    "    where the model considers the results of the tokens with top_p\n",
    "    probability mass. So 0.1 means only the tokens comprising the top 10%\n",
    "    probability mass are considered. Recommended to use top_p or\n",
    "    temperature but not both.\n",
    "  frequency_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on their existing frequency in the text so far, decreasing the model's\n",
    "    likelihood to repeat the same line verbatim.\n",
    "  presence_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on whether they appear in the text so far, increasing the model's\n",
    "    likelihood to talk about new topics.\n",
    "  stop: str\n",
    "    A string where the API will stop generating further tokens.\n",
    "  logit_bias: dict, str\n",
    "    Modify the likelihood of specified tokens appearing in the completion.\n",
    "    Pass a JSON string like '{\"1712\":-100, \"892\":-100, \"1489\":-100}'\n",
    "  seed: int\n",
    "    Integer seed to attempt to sample deterministically\n",
    "  logprobs: int\n",
    "    Include the log probabilities of most likely N per token\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```\n",
    "\n",
    "OpenAI embedding models\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm embed-models\n",
    "ada-002 (aliases: ada)\n",
    "3-small\n",
    "3-large\n",
    "3-small-512\n",
    "3-large-256\n",
    "3-large-1024\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b41ae6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_llm(prompt):\n",
    "    binary_path = \"/usr/local/bin/llm\"\n",
    "    command = [binary_path, prompt]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        \n",
    "        print(\"LLM Response:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"Standard Error:\")\n",
    "            print(result.stderr)\n",
    "        \n",
    "        # print(f\"Return Code: {result.returncode}\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        print(f\"Standard Output: {e.stdout}\")\n",
    "        print(f\"Standard Error: {e.stderr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a907cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
      "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
      "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
      "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
      "OpenAI Chat: gpt-4-1106-preview\n",
      "OpenAI Chat: gpt-4-0125-preview\n",
      "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
      "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
      "OpenAI Chat: gpt-4o (aliases: 4o)\n",
      "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
      "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
      "OpenAI Chat: groq-openai-llama3\n",
      "OpenAI Chat: groq-openai-llama3-8b\n",
      "Anthropic Messages: claude-3-opus-20240229 (aliases: claude-3-opus)\n",
      "Anthropic Messages: claude-3-sonnet-20240229 (aliases: claude-3-sonnet)\n",
      "Anthropic Messages: claude-3-haiku-20240307 (aliases: claude-3-haiku)\n",
      "Anthropic Messages: claude-3-5-sonnet-20240620 (aliases: claude-3.5-sonnet)\n",
      "GgufChatModel: gguf/Meta-Llama-3.1-8B-Instruct-Q4_K_M (aliases: llama-3.1-8b-instruct, l31i)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"models\"\n",
    "run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9fa8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "Sure! To compute the lowest common multiple (LCM) of two integers, you can use the relationship between the greatest common divisor (GCD) and LCM, which is given by the formula:\n",
      "\n",
      "\\[ \\text{LCM}(a, b) = \\frac{|a \\times b|}{\\text{GCD}(a, b)} \\]\n",
      "\n",
      "In Python, we can implement this using simple functions. Here's how you could write the LCM function along with a function to run 5 test cases:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def lcm(a, b):\n",
      "    \"\"\"Compute the lowest common multiple of two integers.\"\"\"\n",
      "    if a == 0 or b == 0:\n",
      "        return 0  # LCM is not defined for zero\n",
      "    return abs(a * b) // math.gcd(a, b)\n",
      "\n",
      "def run_tests():\n",
      "    \"\"\"Run test cases for the LCM function.\"\"\"\n",
      "    test_cases = [\n",
      "        (4, 5),      # LCM is 20\n",
      "        (12, 15),    # LCM is 60\n",
      "        (7, 3),      # LCM is 21\n",
      "        (0, 5),      # LCM should be 0\n",
      "        (-4, 6)      # LCM is 12\n",
      "    ]\n",
      "    \n",
      "    for a, b in test_cases:\n",
      "        print(f\"LCM of {a} and {b} is: {lcm(a, b)}\")\n",
      "\n",
      "# Run the tests\n",
      "run_tests()\n",
      "```\n",
      "\n",
      "In this example:\n",
      "\n",
      "- The `lcm` function calculates the lowest common multiple by first checking for zero, as the LCM is not defined with zero.\n",
      "- The `run_tests` function contains 5 predefined test cases and prints out the results for each case.\n",
      "\n",
      "You can run this code in your Python environment, and it will output the result of each LCM calculation based on the test cases provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A function that computes the lowest common multiples of two integers, and a function that runs 5 test cases of the lowest common multiple function\"\n",
    "run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3cde65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcm(15, 20) = 60\n",
      "lcm(9, 28) = 252\n",
      "lcm(5, 0) = 0\n",
      "lcm(0, 10) = 0\n",
      "lcm(12, 15) = 60\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def lcm(a, b):\n",
    "    \"\"\"Calculate the least common multiple of two integers a and b.\"\"\"\n",
    "    if a == 0 or b == 0:\n",
    "        return 0  # LCM of zero with any number is defined as zero\n",
    "    \n",
    "    return abs(a * b) // math.gcd(a, b)\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Run a set of test cases for the lcm function.\"\"\"\n",
    "    test_cases = [\n",
    "        (15, 20),  # Expected LCM: 60\n",
    "        (9, 28),   # Expected LCM: 252\n",
    "        (5, 0),    # Expected LCM: 0 (with zero)\n",
    "        (0, 10),   # Expected LCM: 0 (with zero)\n",
    "        (12, 15)   # Expected LCM: 60\n",
    "    ]\n",
    "    \n",
    "    for a, b in test_cases:\n",
    "        print(f\"lcm({a}, {b}) = {lcm(a, b)}\")\n",
    "\n",
    "# Run the tests\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6ed2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "Selv om jeg ikke kan fange essensen til Herman Wildenvey perfekt, kan jeg pr√∏ve √• skrive et dikt inspirert av hans stil. Her er et dikt p√• norsk:\n",
      "\n",
      "---\n",
      "\n",
      "**Ved Kysten**\n",
      "\n",
      "Under himmelens dype bl√•,  \n",
      "der b√∏lger hvisker gamle s√•r,  \n",
      "st√•r jeg alene, mens vinden r√•r,  \n",
      "og minner svinner som skum av √•r.\n",
      "\n",
      "Det er kveld, og solen synker,  \n",
      "skygger danser der fjellene blinker,  \n",
      "et hjerte fylt av dr√∏mmer og lengsel,  \n",
      "i horisonten, en lysning, en sengsel.\n",
      "\n",
      "M√•nen vokter sitt stjernespeil,  \n",
      "hvor natten skaper sitt stille seil,  \n",
      "i det fjerne, en melodi s√• kj√¶r,  \n",
      "som hvisker h√•p i den myke v√¶r.\n",
      "\n",
      "√Ö, havets sang i mitt indre bor,  \n",
      "en historie om lengsel, om tapte kor,  \n",
      "men i hver b√∏lges bl√∏te klem,  \n",
      "finner jeg styrke til √• starte igjen.\n",
      "\n",
      "S√• la meg st√• her, i lyset fra stjernene,  \n",
      "med sjelen fri, i naturens garnene,  \n",
      "for i hver b√∏lge, i hver bris som suser,  \n",
      "lever min dr√∏m, som aldri vil fusere.\n",
      "\n",
      "--- \n",
      "\n",
      "H√•per dette diktet fanger noe av Wildenveys √•nd!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poet = \"Herman Wildenvvey\"\n",
    "prompt = f\"Write a poem in the style of {poet} in Norwegian\"\n",
    "run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87aaf159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hvordan p√•virker diabetes insulinproduksjonen?', 'Hvilke matvarer b√∏r diabetikere unng√•?', 'Hvordan fungerer insulinpumper?', 'Hvilke √∏velser er trygge for diabetikere?', 'Hvordan takle depresjon som f√∏lge av diabetes?']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Temabasert ordliste\n",
    "temaer = {\n",
    "    \"sykdomsmekanismer\": [\"Hva er diabetes?\", \"Hvordan p√•virker diabetes insulinproduksjonen?\"],\n",
    "    \"kostholdsr√•d\": [\"Hvilke matvarer b√∏r diabetikere unng√•?\", \"Hvordan balansere karbohydrater?\"],\n",
    "    \"medisinering\": [\"Hvilke medisiner brukes vanligvis til √• behandle type 2 diabetes?\", \"Hvordan fungerer insulinpumper?\"],\n",
    "    \"livsstil\": [\"Hvilke √∏velser er trygge for diabetikere?\", \"Hvordan kan stress p√•virke blodsukkerniv√•et?\"],\n",
    "    \"psykologisk st√∏tte\": [\"Hvordan kan jeg snakke med familien min om min diabetes?\", \"Hvordan takle depresjon som f√∏lge av diabetes?\"]\n",
    "}\n",
    "\n",
    "# Sp√∏rsm√•lsgenerator\n",
    "def generer_sp√∏rsm√•l(tema):\n",
    "    sp√∏rsm√•l = random.choice(temaer[tema])\n",
    "    return sp√∏rsm√•l\n",
    "\n",
    "# Generere et sett med sp√∏rsm√•l\n",
    "def generer_sp√∏rsm√•lsett():\n",
    "    sp√∏rsm√•lsett = []\n",
    "    for tema in temaer.keys():\n",
    "        sp√∏rsm√•lsett.append(generer_sp√∏rsm√•l(tema))\n",
    "    return sp√∏rsm√•lsett\n",
    "\n",
    "# Eksempel p√• genererte sp√∏rsm√•l\n",
    "print(generer_sp√∏rsm√•lsett())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0bf3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_liste = generer_sp√∏rsm√•lsett()\n",
    "len(spm_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6e0a020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spm 0: Hva er diabetes?\n",
      "LLM Response:\n",
      "Svar p√• Spm 0: Diabetes er en kronisk sykdom som oppst√•r n√•r kroppen ikke klarer √• produsere tilstrekkelig insulin, eller n√•r kroppen ikke kan bruke insulin effektivt. Insulin er et hormon som regulerer blodsukkerniv√•et. Det finnes hovedsakelig to typer diabetes: type 1, som vanligvis utvikles i barndommen eller ung voksen alder og krever insulintilf√∏rsel, og type 2, som oftere utvikles hos voksne og ofte kan kontrolleres med kosthold, trening og medisiner. Ubehandlet diabetes kan f√∏re til alvorlige helsekomplikasjoner som hjerte- og karsykdommer, nyresykdom, nerveproblemer og synsforstyrrelser. Det er viktig √• ha god kontroll over blodsukkeret for √• forebygge disse komplikasjonene. Regelmessig oppf√∏lging hos helsepersonell og en sunn livsstil er avgj√∏rende for personer med diabetes.\n",
      "\n",
      "Spm 1: Hvilke matvarer b√∏r diabetikere unng√•?\n",
      "LLM Response:\n",
      "Svar p√• Spm 1: Diabetikere b√∏r unng√• matvarer med h√∏yt innhold av sukker og raske karbohydrater, som sukkers√∏te snacks, brus og bakevarer laget med hvitt mel. Bearbeidede matvarer og hurtigmat b√∏r ogs√• begrenses, da de ofte inneholder usunne fettstoffer og tilsatt sukker. Dessuten er det lurt √• unng√• mat med h√∏yt glykemisk indeks, som hvit ris, potetmos og visse frokostblandinger. R√∏dt kj√∏tt og bearbeidede kj√∏ttprodukter kan v√¶re mindre gunstige, s√• det anbefales √• velge magre proteinkilder som fisk, kylling og belgfrukter. Endelig b√∏r man v√¶re forsiktig med alkohol, da det kan p√•virke blodsukkerniv√•et. Fokuser p√• helfrokost, gr√∏nnsaker og fullkornsprodukter for bedre blodsukkerkontroll.\n",
      "\n",
      "Spm 2: Hvordan fungerer insulinpumper?\n",
      "LLM Response:\n",
      "Svar p√• Spm 2: Insulinpumper er en enhet som leverer kontinuerlig insulin til personer med diabetes for √• regulere blodsukkerniv√•et. Pumpen er festet til kroppen og har en liten kateter som plasseres under huden, vanligvis p√• magen. Den bruker en liten motor til √• gi insulin i sm√•, n√∏yaktige doser, enten kontinuerlig (basaldose) eller ved behov (bolusdose) n√•r man spiser. Brukeren kan programmere pumpen til √• tilpasse insulindosene etter aktivitetsniv√• og kosthold, noe som gir en mer fleksibel livsstil. Insulinpumpen krever regelmessig overv√•king av blodsukkerniv√•er og justeringer av innstillinger for √• opprettholde god glykemisk kontroll. Den kan bidra til √• redusere risikoen for b√•de h√∏yt og lavt blodsukker, noe som er viktig for √• forebygge komplikasjoner relatert til diabetes.\n",
      "\n",
      "Spm 3: Hvordan kan stress p√•virke blodsukkerniv√•et?\n",
      "LLM Response:\n",
      "Svar p√• Spm 3: Stress kan ha en betydelig innvirkning p√• blodsukkerniv√•et. N√•r kroppen opplever stress, aktiveres det sympatiske nervesystemet, noe som f√∏rer til produksjon av stresshormoner som adrenalin og kortisol. Disse hormonene stimulerer leveren til √• frigj√∏re glukose i blodet for √• gi rask energi, noe som kan f√∏re til h√∏ye blodsukkerniv√•er. Langvarig stress kan f√∏re til kronisk forh√∏yede glukoseniv√•er, noe som kan √∏ke risikoen for insulinresistens og type 2-diabetes. I tillegg kan stress p√•virke kostholdet og livsstilen, som ofte f√∏rer til usunne matvalg og mindre fysisk aktivitet, noe som ytterligere kan forverre blodsukkerkontrollen. Det er derfor viktig √• h√•ndtere stress p√• en sunn m√•te for √• opprettholde stabile blodsukkerniv√•er.\n",
      "\n",
      "Spm 4: Hvordan takle depresjon som f√∏lge av diabetes?\n",
      "LLM Response:\n",
      "Svar p√• Spm 4: √Ö takle depresjon som f√∏lge av diabetes krever en helhetlig tiln√¶rming. F√∏rst er det viktig √• s√∏ke profesjonell hjelp, enten gjennom psykolog, lege eller diabetesbehandlere. Utforsk st√∏ttegrupper for b√•de diabetes og mental helse, da dette kan gi verdifull st√∏tte og erfaringer fra andre. Regelmessig fysisk aktivitet og et balansert kosthold kan forbedre b√•de fysiske og mentale helse. Pr√∏v mindfulness eller meditasjon for √• redusere stress og forbedre livskvalitet. Sett realistiske m√•l for diabetesbehandling og feire sm√• seire. S√∏rg for √• ha et godt nettverk av familie og venner som kan gi st√∏tte. V√¶r √•pen om f√∏lelsene dine, og husk at det er normalt √• f√∏le seg overveldet. Behovet for √• h√•ndtere b√•de diabetes og psykisk helse er viktig for √• forbedre livskvaliteten.\n",
      "\n",
      "CPU times: user 38.9 ms, sys: 91 ms, total: 130 ms\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, spm in enumerate(spm_liste):\n",
    "    print(f'Spm {i}: {spm}')\n",
    "    prompt = f\"{spm}. Svar p√• norsk. Bruk max 150 ord. Start med 'Svar p√• Spm {i}'. Ikke bruk avsnitt. -m gpt-4o-mini\"\n",
    "    run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07e973ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spm 0: Hva er diabetes?\n",
      "LLM Response:\n",
      "Svar p√• Spm 0: Diabetes er en kronisk sykdom som oppst√•r n√•r kroppen har problemer med √• regulere blodsukkerniv√•et. Dette kan skyldes at bukspyttkjertelen ikke produserer nok insulin, et hormon som er n√∏dvendig for √• transportere glukose inn i cellene, eller at kroppens celler ikke reagerer normalt p√• insulin. Det finnes hovedsakelig to typer diabetes: type 1, som ofte oppst√•r i barndommen eller ungdommen, og type 2, som vanligvis utvikler seg senere i livet og er sterkt knyttet til overvekt og livsstil. Symptomer inkluderer √∏kt t√∏rste, hyppig urinering, tretthet og s√•r som tar lang tid √• gro. Behandling kan inneb√¶re livsstilsendringer, medisiner og insulinbehandling, avhengig av type og alvorlighetsgrad. Tidlig diagnose og behandling er viktig for √• unng√• alvorlige komplikasjoner.\n",
      "\n",
      "Spm 1: Hvilke matvarer b√∏r diabetikere unng√•?\n",
      "LLM Response:\n",
      "Svar p√• Spm 1: Diabetikere b√∏r unng√• matvarer med h√∏yt sukkerinnhold, som sukkerholdige drikker, godteri, og bakevarer laget med hvitt mel. Raffinerte karbohydrater, som hvitt br√∏d og pasta, kan ogs√• f√∏re til hurtige blodsukker√∏kninger. I tillegg b√∏r de begrense inntaket av mettet fett og transfett, som finnes i frityrstekte matvarer og behandlet snacks. Alkohol kan ogs√• p√•virke blodsukkeret, s√• moderat inntak er viktig. For verkt√∏y er det lurt √• begrense inntaket av h√∏y-glykemisk indekse matvarer som poteter og enkelte frokostblandinger. Fokus p√• hel mat, fiber, og komplekse karbohydrater er √• foretrekke for √• opprettholde stabilt blodsukker.\n",
      "\n",
      "Spm 2: Hvordan fungerer insulinpumper?\n",
      "LLM Response:\n",
      "Svar p√• Spm 2: Insulinpumper er en enhet som gir kontinuerlig tilf√∏rsel av insulin til personer med diabetes. Pumpen leverer insulin gjennom en kateter, som settes inn i huden, vanligvis i magen eller l√•ret. Den programmeres til √• gi en basaldose insulin hele d√∏gnet, samt ekstra bolusdoser ved m√•ltider for √• kontrollere blodsukkerniv√•et. Brukeren kan justere innstillingene via en skjerm, noe som gir st√∏rre fleksibilitet enn injeksjoner. Insulinpumpen m√•les kontinuerlig i forbindelse med blodsukkeret, og mange modeller kan kobles til kontinuerlige glukosem√•lere for automatisk justering. Pumpesystemet forbedrer livskvaliteten ved √• redusere stikk og gi mer presis insulinregulering. Det er viktig √• f√∏lge opp med jevnlige m√•linger og tilpasninger for √• oppn√• optimal blodsukkerkontroll.\n",
      "\n",
      "Spm 3: Hvordan kan stress p√•virke blodsukkerniv√•et?\n",
      "LLM Response:\n",
      "Svar p√• Spm 3: Stress kan p√•virke blodsukkerniv√•et p√• flere m√•ter. N√•r kroppen opplever stress, aktiveres det sympatiske nervesystemet, som kan f√∏re til frigj√∏ring av stresshormoner som adrenalin og kortisol. Disse hormonene fremmer omdannelsen av glykogen til glukose i leveren, noe som √∏ker blodsukkerniv√•et for √• gi rask energi til kroppen. Langvarig stress kan imidlertid resultere i kronisk forh√∏yede blodsukkerniv√•er, hvilket kan v√¶re problematisk, spesielt for personer med diabetes. Stress kan ogs√• p√•virke livsstilsvalg og spisevaner, noe som ytterligere kan forverre blodsukkerreguleringen. Samlet sett kan stress v√¶re en betydelig faktor i blodsukkerbalansen, og det er viktig √• h√•ndtere stress for √• opprettholde et stabilt blodsukkerniv√•.\n",
      "\n",
      "Spm 4: Hvordan takle depresjon som f√∏lge av diabetes?\n",
      "LLM Response:\n",
      "Svar p√• Spm 4: √Ö takle depresjon som f√∏lge av diabetes kan v√¶re utfordrende, men det finnes strategier som kan hjelpe. Det er viktig √• s√∏ke profesjonell hjelp, som terapi eller r√•dgivning, for √• f√• verkt√∏y til √• h√•ndtere f√∏lelsene. Oppretthold en sunn livsstil med et balansert kosthold og regelmessig mosjon, da dette kan forbedre b√•de fysisk og psykisk helse. Vei viktigheten av st√∏tte fra familie og venner; del f√∏lelser og erfaringer med dem. Sett realistiske m√•l for blodsukkerkontroll og ta sm√• skritt mot bedre helse. Mindfulness og avspenningsteknikker kan ogs√• redusere angst og depresjon. Husk at det er normalt √• oppleve slike f√∏lelser, og at det er hjelp √• f√•. Prioriter egenomsorg og v√¶r t√•lmodig med deg selv i prosessen.\n",
      "\n",
      "CPU times: user 37.8 ms, sys: 88.9 ms, total: 127 ms\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, spm in enumerate(spm_liste):\n",
    "    print(f'Spm {i}: {spm}')\n",
    "    prompt = f\"{spm}. Svar p√• norsk. Bruk max 150 ord. Start med 'Svar p√• Spm {i}'. Ikke bruk avsnitt. -m l31i\"\n",
    "    run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16d9195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spm 0: Hva er diabetes?\n",
      "LLM Response:\n",
      "Svar p√• Spm 0: Diabetes er en kronisk sykdom som oppst√•r n√•r kroppen ikke klarer √• produsere tilstrekkelig insulin, eller n√•r cellene ikke reagerer effektivt p√• insulin. Dette f√∏rer til h√∏ye blodsukkerniv√•er. Det finnes hovedsakelig to typer diabetes: type 1, som ofte oppst√•r i barndommen eller tidlig voksenliv og skyldes en autoimmun reaksjon som √∏delegger insulinproduserende celler i bukspyttkjertelen, og type 2, som oftest utvikler seg hos voksne og er knyttet til livsstilsfaktorer som overvekt og mangel p√• fysisk aktivitet. Diabetes kan f√∏re til alvorlige helseproblemer som hjerte- og karsykdommer, nyreskader og nerveskader hvis den ikke behandles. Behandling inkluderer kosthold, mosjon, blodsukkerkontroll og medikamenter, avhengig av type og alvorlighetsgrad. Tidlig diagnose og behandling er viktig for √• h√•ndtere sykdommen effektivt.\n",
      "\n",
      "Spm 1: Hvordan balansere karbohydrater?\n",
      "LLM Response:\n",
      "Svar p√• Spm 1: For √• balansere karbohydrater, fokuser p√• kvalitet og mengde. Velg komplekse karbohydrater som fullkorn, frukt og gr√∏nnsaker, som gir langsom energi og er rike p√• fiber. Unng√• enkle sukkerarter fra usunne kilder som brus og godteri. Se p√• porsjonsst√∏rrelser og fordel karbohydratinntaket jevnt gjennom dagen for √• unng√• blodsukkerstigning. Kombiner karbohydrater med proteiner og sunne fettkilder for √• stabilisere blodsukkeret og √∏ke metthetsf√∏lelsen. Lytt til kroppen din og tilpass inntaket etter aktivitetsniv√•et; eldre og mindre aktive personer trenger ofte f√¶rre karbohydrater. Planlegging av m√•ltider og snacks kan ogs√• hjelpe med √• opprettholde en sunn balanse.\n",
      "\n",
      "Spm 2: Hvilke medisiner brukes vanligvis til √• behandle type 2 diabetes?\n",
      "LLM Response:\n",
      "Svar p√• Spm 2: Vanlige medisiner for behandling av type 2 diabetes inkluderer metformin, som er f√∏rstevalget og bidrar til √• redusere blodsukkeret ved √• √∏ke insulinf√∏lsomheten og hemme glukoseproduksjonen i leveren. Andre medikamenter inkluderer sulfonylurea (som glibenklamid og glipizid), som stimulerer bukspyttkjertelen til √• produsere mer insulin, og DPP-4-hemmere (som sitagliptin), som √∏ker insulinutskillelsen og reduserer glukagon. SGLT2-hemmere (som canagliflozin) bidrar til √• fjerne sukker gjennom urinen, mens GLP-1-reseptoragonister (som liraglutid) fremmer insulinproduksjon ved h√∏yere blodsukkerniv√• og gir vekttap. Insulinbehandling kan ogs√• v√¶re n√∏dvendig i mer avanserte tilfeller. Det er viktig at behandlingen tilpasses individuelt.\n",
      "\n",
      "Spm 3: Hvilke √∏velser er trygge for diabetikere?\n",
      "LLM Response:\n",
      "Svar p√• Spm 3: Diabetikere kan trygt utf√∏re variasjoner av aerobic trening, styrketrening og fleksibilitets√∏velser. G√•ende, sykling og sv√∏mming er gode kardiovaskul√¶re aktiviteter som forbedrer blodsukkerkontrollen. Styrketrening, som inkluderer vekthevning eller kroppen som motstand, kan ogs√• v√¶re fordelaktig da det bidrar til muskelmasse og stoffskifte. Yoga og stretching √∏ker fleksibilitet og reduserer stress, noe som kan ha positiv innvirkning p√• blodsukkeret. Det er viktig √• konsultere helsepersonell f√∏r man begynner med et nytt treningsprogram, og v√¶re oppmerksom p√• blodsukkerniv√•et f√∏r, under og etter trening. √Ö drikke rikelig med vann og ha klare snackalternativer tilgjengelig kan ogs√• v√¶re lurt for √• unng√• hypoglykemi. Trening b√∏r tilpasses den enkeltes helsetilstand og fysiske kapasitet.\n",
      "\n",
      "Spm 4: Hvordan kan jeg snakke med familien min om min diabetes?\n",
      "LLM Response:\n",
      "Svar p√• Spm 4. Det kan v√¶re en utfordring √• snakke med familien om diabetes, men √•penhet er viktig. Start med √• forklare hva diabetes er, og hvordan det p√•virker hverdagen din. Del dine erfaringer, og v√¶r √¶rlig om f√∏lelsene dine knyttet til tilstanden. Forklar hvordan de kan st√∏tte deg, enten det gjelder kosthold, trening eller √• v√¶re bevisste p√• symptomene. Oppfordre dem til √• stille sp√∏rsm√•l, og v√¶r forberedt p√• at de kanskje ikke vet mye om sykdommen fra f√∏r. Del gjerne informasjonskilder om diabetes, slik at de kan forst√• bedre. Det kan ogs√• v√¶re nyttig √• involvere en lege eller spesialist som kan gi mer innsikt. Husk at m√•lsettingen er √• bygge forst√•else og st√∏tte, s√• v√¶r t√•lmodig og lyttende i samtalen.\n",
      "\n",
      "CPU times: user 72.4 ms, sys: 79.9 ms, total: 152 ms\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, spm in enumerate(spm_liste):\n",
    "    print(f'Spm {i}: {spm}')\n",
    "    prompt = f\"{spm}. Svar p√• norsk. Bruk max 150 ord. Start med 'Svar p√• Spm {i}'. Ikke bruk avsnitt. -m claude-3.5-sonnet\"\n",
    "    run_llm(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25a120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.3",
   "language": "sage",
   "name": "sagemath-10.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
