{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dedd2a6",
   "metadata": {},
   "source": [
    "# 07-ai-in-sage.ipynb\n",
    "\n",
    "\n",
    "A.L. 2023-08-21 (Ubuntu 2022.04, Sage 10.1)<br>\n",
    "A.L. 2024-07-22 (MacBook Air 11 inch, Mid 2012, MacOs 10.15.7, Sage 10.3, using `brew install llm`)<br>\n",
    "A.L. 2024-07-24 (MacBook Air 11 inch, Mid 2012, MacOs 10.15.7, Sage 10.3, using `Llama 3.1 8B`)<br>\n",
    "A.L. 2024-07-25 (MacBook Pro 16 inch, 2019, MacOs Sonoma 14.5, Sage 10.3, using `Llama 3.1 8B`)<br>\n",
    "\n",
    "\n",
    "If you've already installed LLM the following set of commands should get you setup with Llama 3.1 8B:\n",
    "```bash\n",
    "    llm install llm-gguf\n",
    "    llm gguf download-model \\\n",
    "      https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf \\\n",
    "      --alias llama-3.1-8b-instruct --alias l31i\n",
    "```\n",
    "\n",
    "This will download a 4.92GB GGUF from lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF on Hugging Face and save it (at least on macOS) to your `~/Library/Application Support/io.datasette.llm/gguf/models` folder.\n",
    "Once installed like that, you can run prompts through the model like so:\n",
    "```bash\n",
    "    llm -m l31i \"five great names for a pet lemur\"\n",
    "```\n",
    "Or use the `llm chat` command to keep the model resident in memory and run an interactive chat session with it:\n",
    "```bash\n",
    "    llm chat -m l31i\n",
    "```\n",
    "\n",
    "### Anthropic Claude 3.5 Sonnet\n",
    "\n",
    "To Get API keys:<be>\n",
    "https://console.anthropic.com/dashboard\n",
    "\n",
    "```bash\n",
    "llm install llm-claude-3\n",
    "llm keys set claude\n",
    "# <Paste key here>\n",
    "\n",
    "# Now list available models\n",
    "llm models\n",
    "# and, to include a list of their options\n",
    "llm models --options\n",
    "# Then run a prompt\n",
    "llm -m claude-3.5-sonnet 'Fun facts about pelicans'\n",
    "llm -m claude-3-haiku-20240307 'say hi in spanish with a flourish'\n",
    "```\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm models          \n",
    "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
    "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
    "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
    "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
    "OpenAI Chat: gpt-4-1106-preview\n",
    "OpenAI Chat: gpt-4-0125-preview\n",
    "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
    "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
    "OpenAI Chat: gpt-4o (aliases: 4o)\n",
    "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
    "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
    "Anthropic Messages: claude-3-opus-20240229 (aliases: claude-3-opus)\n",
    "Anthropic Messages: claude-3-sonnet-20240229 (aliases: claude-3-sonnet)\n",
    "Anthropic Messages: claude-3-haiku-20240307 (aliases: claude-3-haiku)\n",
    "Anthropic Messages: claude-3-5-sonnet-20240620 (aliases: claude-3.5-sonnet)\n",
    "GgufChatModel: gguf/Meta-Llama-3.1-8B-Instruct-Q4_K_M (aliases: llama-3.1-8b-instruct, l31i)\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```\n",
    " \n",
    "\n",
    "### jupyter-ai\n",
    "\n",
    "- https://github.com/jupyterlab/jupyter-ai\n",
    "\n",
    "- https://openai.com/api/\n",
    "\n",
    "You can find your API key at https://platform.openai.com/account/api-keys.\n",
    "\n",
    "\n",
    "```\n",
    "echo \"export OPENAI_API_KEY='yourkey'\" >> ~/.zshrc   (or  ~/.bashrc )\n",
    "source ~/.zshrc\n",
    "echo $OPENAI_API_KEY\n",
    "```\n",
    "or\n",
    "```\n",
    "import os\n",
    "import openai\n",
    " \n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "```\n",
    "\n",
    "\n",
    "See also: https://sagemanifolds.obspm.fr/install_ubuntu.html\n",
    "\n",
    "Check sage installation and start a Jupyter notebook with the SageMath 9.6 kernel:\n",
    "\n",
    "```\n",
    "sage -c 'print(version())\n",
    "sage -notebook\n",
    "```\n",
    "\n",
    "\n",
    "Installing R-packages:\n",
    "```\n",
    "sage -R\n",
    "\n",
    "> install.packages(\"lme4\")\n",
    "```\n",
    "\n",
    "Installing Python packages (in the sage kernel):\n",
    "```\n",
    "> sage --pip install pandas\n",
    "> sage --pip install seaborn\n",
    "> sage --pip install networkx\n",
    "> sage --pip install igraph\n",
    "> # sage --pip install pycairo\n",
    "> # sage --pip install cairocffi\n",
    "> # sage --pip install leidenalg\n",
    "> sage --pip install jupyterlab\n",
    "> sage --pip install altair vega_datasets      # https://altair-viz.github.io/index.html\n",
    "> sage --pip install pygraphviz\n",
    "\n",
    "> sage --pip install openai\n",
    "> sage --pip install jupyter_ai\n",
    "> sage --pip install python-dotenv\n",
    "```\n",
    "\n",
    "```\n",
    "%reload_ext jupyter_ai\n",
    "\n",
    "%%ai chatgpt --format code\n",
    "A function that computes the lowest common multiples of two integers, and a function that runs 5 test cases of the lowest common multiple function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c30bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211036a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] MODEL_ID\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  -m, --model-parameters TEXT     A JSON value that specifies extra values\n",
      "                                  that will be passed to the model. The\n",
      "                                  accepted value parsed to a dict, unpacked\n",
      "                                  and passed as-is to the provider class.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f490af14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:anthropic.claude-v1`</li><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li></ul> |\n",
       "| `anthropic` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`anthropic:claude-v1`</li><li>`anthropic:claude-v1.0`</li><li>`anthropic:claude-v1.2`</li><li>`anthropic:claude-2`</li><li>`anthropic:claude-2.0`</li><li>`anthropic:claude-instant-v1`</li><li>`anthropic:claude-instant-v1.0`</li><li>`anthropic:claude-instant-v1.2`</li></ul> |\n",
       "| `anthropic-chat` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`anthropic-chat:claude-v1`</li><li>`anthropic-chat:claude-v1.0`</li><li>`anthropic-chat:claude-v1.2`</li><li>`anthropic-chat:claude-2`</li><li>`anthropic-chat:claude-2.0`</li><li>`anthropic-chat:claude-instant-v1`</li><li>`anthropic-chat:claude-instant-v1.0`</li><li>`anthropic-chat:claude-instant-v1.2`</li></ul> |\n",
       "| `azure-chat-openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-0301`</li><li>`openai-chat:gpt-3.5-turbo-0613`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-3.5-turbo-16k`</li><li>`openai-chat:gpt-3.5-turbo-16k-0613`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-32k`</li><li>`openai-chat:gpt-4-32k-0613`</li><li>`openai-chat:gpt-4-1106-preview`</li></ul> |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n"
      ],
      "text/plain": [
       "<jupyter_ai_magics.magics.TextOrMarkdown object at 0x16ff54750>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201a507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n"
      ],
      "text/plain": [
       "<jupyter_ai_magics.magics.TextOrMarkdown object at 0x16ff644d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a18544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \n",
       "\\frac{\\partial u}{\\partial t} = \\alpha \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right)\n",
       "$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/latex": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f math\n",
    "Generate the 2D heat equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958e0b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt --format code\n",
    "A function that computes the lowest common multiples of two integers, and a function that runs 5 test cases of the lowest common multiple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b565bf8-0663-4c9c-9d2d-69b11f5be20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcm(a, b):\n",
    "    def gcd(a, b):\n",
    "        while b:\n",
    "            a, b = b, a % b\n",
    "        return a\n",
    "    return abs(a*b) // gcd(a, b)\n",
    "\n",
    "def test_lcm():\n",
    "    test_cases = [(3, 5), (10, 15), (7, 9), (18, 24), (30, 40)]\n",
    "    \n",
    "    for a, b in test_cases:\n",
    "        print(f\"LCM of {a} and {b} is: {lcm(a, b)}\")\n",
    "\n",
    "test_lcm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5224b3-0633-4177-a58d-e9cf03da2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcm(a, b):\n",
    "    if a == 0 or b == 0:\n",
    "        return 0\n",
    "    max_num = max(a, b)\n",
    "    while True:\n",
    "        if max_num % a == 0 and max_num % b == 0:\n",
    "            return max_num\n",
    "        max_num += 1\n",
    "\n",
    "def test_lcm():\n",
    "    test_cases = [(3, 5), (10, 15), (7, 9), (20, 25), (18, 24)]\n",
    "    for a, b in test_cases:\n",
    "        result = lcm(a, b)\n",
    "        print(f\"LCM of {a} and {b} is {result}\")\n",
    "\n",
    "test_lcm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55989eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCM of 3 and 5 is 15\n",
      "LCM of 9 and 12 is 36\n",
      "LCM of 8 and 14 is 56\n",
      "LCM of 15 and 20 is 60\n",
      "LCM of 24 and 36 is 72\n",
      "LCM of 9 and 28 is 252\n"
     ]
    }
   ],
   "source": [
    "def lcm(a, b):\n",
    "    # Find the maximum of a and b\n",
    "    if a > b:\n",
    "        max_num = a\n",
    "    else:\n",
    "        max_num = b\n",
    "\n",
    "    # Iterate and find the lowest common multiple\n",
    "    while True:\n",
    "        if max_num % a == 0 and max_num % b == 0:\n",
    "            return max_num\n",
    "        max_num += 1\n",
    "\n",
    "def run_lcm_tests():\n",
    "    # Run test cases\n",
    "    test_cases = [(3, 5), (9, 12), (8, 14), (15, 20), (24, 36), (9,28)]\n",
    "    \n",
    "    for a, b in test_cases:\n",
    "        result = lcm(a, b)\n",
    "        print(f\"LCM of {a} and {b} is {result}\")\n",
    "\n",
    "# Run the test cases\n",
    "run_lcm_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d495c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "poet = \"Herman Wildenvvey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52b6dee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Vindens Sang\n",
       "\n",
       "I skogen hører jeg vinden synge,\n",
       "En melodi så vakker og ren,\n",
       "Gjennom trærne den sakte svinge,\n",
       "Og min sjel den fanger med en gang.\n",
       "\n",
       "Naturens symfoni av sus og brus,\n",
       "Fyller mitt hjerte med glede og ro,\n",
       "Som en elv av toner som aldri tar slutt,\n",
       "En evighet av fred og harmoni.\n",
       "\n",
       "Så la meg bli ett med denne sang,\n",
       "La meg føle vinden i mitt indre,\n",
       "For i naturen finner jeg min trang,\n",
       "Til å være fri og leve uten hindre."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt \n",
    "Write a poem in the style of {poet} in Norwegian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247ddeb",
   "metadata": {},
   "source": [
    "## llm   Simon Willison\n",
    "\n",
    "https://github.com/simonw/llm\n",
    "\n",
    "https://llm.datasette.io/en/stable/usage.html\n",
    "\n",
    "```bash\n",
    "If you have an OpenAI API key you can get started using the OpenAI models right away.\n",
    "\n",
    "As an alternative to OpenAI, you can install plugins to access models by other providers, including models that can be installed and run on your own device.\n",
    "\n",
    "Save your OpenAI API key like this:\n",
    "\n",
    "llm keys set openai\n",
    "This will prompt you for your key like so:\n",
    "\n",
    "Enter key: <paste here>\n",
    "```\n",
    "\n",
    "Now that you've saved a key you can run a prompt like this:\n",
    "```bash\n",
    "llm \"Five cute names for a pet penguin\"\n",
    "```\n",
    "\n",
    "The OpenAI API key is saved in keys.json:\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % ls -l /Users/arvid/Library/Application\\ Support/io.datasette.llm\n",
    "total 136\n",
    "-rw-------  1 arvid  staff    146 Jul 20 17:47 keys.json\n",
    "-rw-r--r--  1 arvid  staff  65536 Jul 20 20:09 logs.db\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm models\n",
    "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
    "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
    "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
    "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
    "OpenAI Chat: gpt-4-1106-preview\n",
    "OpenAI Chat: gpt-4-0125-preview\n",
    "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
    "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
    "OpenAI Chat: gpt-4o (aliases: 4o)\n",
    "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
    "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
    "```\n",
    "\n",
    "To describe how the code a file works, try this:\n",
    "```bash\n",
    "cat mycode.py | llm -s \"Explain this code\"\n",
    "```\n",
    "\n",
    "Additional examples and functions:\n",
    "\n",
    "```bash\n",
    "llm 'Ten names for cheesecakes' -m gpt-4o\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm models --options\n",
    "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
    "  temperature: float\n",
    "    What sampling temperature to use, between 0 and 2. Higher values like\n",
    "    0.8 will make the output more random, while lower values like 0.2 will\n",
    "    make it more focused and deterministic.\n",
    "  max_tokens: int\n",
    "    Maximum number of tokens to generate.\n",
    "  top_p: float\n",
    "    An alternative to sampling with temperature, called nucleus sampling,\n",
    "    where the model considers the results of the tokens with top_p\n",
    "    probability mass. So 0.1 means only the tokens comprising the top 10%\n",
    "    probability mass are considered. Recommended to use top_p or\n",
    "    temperature but not both.\n",
    "  frequency_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on their existing frequency in the text so far, decreasing the model's\n",
    "    likelihood to repeat the same line verbatim.\n",
    "  presence_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on whether they appear in the text so far, increasing the model's\n",
    "    likelihood to talk about new topics.\n",
    "  stop: str\n",
    "    A string where the API will stop generating further tokens.\n",
    "  logit_bias: dict, str\n",
    "    Modify the likelihood of specified tokens appearing in the completion.\n",
    "    Pass a JSON string like '{\"1712\":-100, \"892\":-100, \"1489\":-100}'\n",
    "  seed: int\n",
    "    Integer seed to attempt to sample deterministically\n",
    "  json_object: boolean\n",
    "    Output a valid JSON object {...}. Prompt must mention JSON.\n",
    "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-1106-preview\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-0125-preview\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4o (aliases: 4o)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
    "  temperature: float\n",
    "  max_tokens: int\n",
    "  top_p: float\n",
    "  frequency_penalty: float\n",
    "  presence_penalty: float\n",
    "  stop: str\n",
    "  logit_bias: dict, str\n",
    "  seed: int\n",
    "  json_object: boolean\n",
    "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
    "  temperature: float\n",
    "    What sampling temperature to use, between 0 and 2. Higher values like\n",
    "    0.8 will make the output more random, while lower values like 0.2 will\n",
    "    make it more focused and deterministic.\n",
    "  max_tokens: int\n",
    "    Maximum number of tokens to generate.\n",
    "  top_p: float\n",
    "    An alternative to sampling with temperature, called nucleus sampling,\n",
    "    where the model considers the results of the tokens with top_p\n",
    "    probability mass. So 0.1 means only the tokens comprising the top 10%\n",
    "    probability mass are considered. Recommended to use top_p or\n",
    "    temperature but not both.\n",
    "  frequency_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on their existing frequency in the text so far, decreasing the model's\n",
    "    likelihood to repeat the same line verbatim.\n",
    "  presence_penalty: float\n",
    "    Number between -2.0 and 2.0. Positive values penalize new tokens based\n",
    "    on whether they appear in the text so far, increasing the model's\n",
    "    likelihood to talk about new topics.\n",
    "  stop: str\n",
    "    A string where the API will stop generating further tokens.\n",
    "  logit_bias: dict, str\n",
    "    Modify the likelihood of specified tokens appearing in the completion.\n",
    "    Pass a JSON string like '{\"1712\":-100, \"892\":-100, \"1489\":-100}'\n",
    "  seed: int\n",
    "    Integer seed to attempt to sample deterministically\n",
    "  logprobs: int\n",
    "    Include the log probabilities of most likely N per token\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```\n",
    "\n",
    "OpenAI embedding models\n",
    "```bash\n",
    "(base) arvid@Arvids-Air ~ % llm embed-models\n",
    "ada-002 (aliases: ada)\n",
    "3-small\n",
    "3-large\n",
    "3-small-512\n",
    "3-large-256\n",
    "3-large-1024\n",
    "(base) arvid@Arvids-Air ~ % \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b41ae6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_llm(prompt):\n",
    "    binary_path = \"/usr/local/bin/llm\"\n",
    "    command = [binary_path, prompt]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        \n",
    "        print(\"LLM Response:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"Standard Error:\")\n",
    "            print(result.stderr)\n",
    "        \n",
    "        # print(f\"Return Code: {result.returncode}\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        print(f\"Standard Output: {e.stdout}\")\n",
    "        print(f\"Standard Error: {e.stderr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a907cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "OpenAI Chat: gpt-3.5-turbo (aliases: 3.5, chatgpt)\n",
      "OpenAI Chat: gpt-3.5-turbo-16k (aliases: chatgpt-16k, 3.5-16k)\n",
      "OpenAI Chat: gpt-4 (aliases: 4, gpt4)\n",
      "OpenAI Chat: gpt-4-32k (aliases: 4-32k)\n",
      "OpenAI Chat: gpt-4-1106-preview\n",
      "OpenAI Chat: gpt-4-0125-preview\n",
      "OpenAI Chat: gpt-4-turbo-2024-04-09\n",
      "OpenAI Chat: gpt-4-turbo (aliases: gpt-4-turbo-preview, 4-turbo, 4t)\n",
      "OpenAI Chat: gpt-4o (aliases: 4o)\n",
      "OpenAI Chat: gpt-4o-mini (aliases: 4o-mini)\n",
      "OpenAI Completion: gpt-3.5-turbo-instruct (aliases: 3.5-instruct, chatgpt-instruct)\n",
      "OpenAI Chat: groq-openai-llama3\n",
      "OpenAI Chat: groq-openai-llama3-8b\n",
      "Anthropic Messages: claude-3-opus-20240229 (aliases: claude-3-opus)\n",
      "Anthropic Messages: claude-3-sonnet-20240229 (aliases: claude-3-sonnet)\n",
      "Anthropic Messages: claude-3-haiku-20240307 (aliases: claude-3-haiku)\n",
      "Anthropic Messages: claude-3-5-sonnet-20240620 (aliases: claude-3.5-sonnet)\n",
      "GgufChatModel: gguf/Meta-Llama-3.1-8B-Instruct-Q4_K_M (aliases: llama-3.1-8b-instruct, l31i)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"models\"\n",
    "run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9fa8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "Sure! To compute the lowest common multiple (LCM) of two integers, you can use the relationship between the greatest common divisor (GCD) and LCM, which is given by the formula:\n",
      "\n",
      "\\[ \\text{LCM}(a, b) = \\frac{|a \\times b|}{\\text{GCD}(a, b)} \\]\n",
      "\n",
      "In Python, we can implement this using simple functions. Here's how you could write the LCM function along with a function to run 5 test cases:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def lcm(a, b):\n",
      "    \"\"\"Compute the lowest common multiple of two integers.\"\"\"\n",
      "    if a == 0 or b == 0:\n",
      "        return 0  # LCM is not defined for zero\n",
      "    return abs(a * b) // math.gcd(a, b)\n",
      "\n",
      "def run_tests():\n",
      "    \"\"\"Run test cases for the LCM function.\"\"\"\n",
      "    test_cases = [\n",
      "        (4, 5),      # LCM is 20\n",
      "        (12, 15),    # LCM is 60\n",
      "        (7, 3),      # LCM is 21\n",
      "        (0, 5),      # LCM should be 0\n",
      "        (-4, 6)      # LCM is 12\n",
      "    ]\n",
      "    \n",
      "    for a, b in test_cases:\n",
      "        print(f\"LCM of {a} and {b} is: {lcm(a, b)}\")\n",
      "\n",
      "# Run the tests\n",
      "run_tests()\n",
      "```\n",
      "\n",
      "In this example:\n",
      "\n",
      "- The `lcm` function calculates the lowest common multiple by first checking for zero, as the LCM is not defined with zero.\n",
      "- The `run_tests` function contains 5 predefined test cases and prints out the results for each case.\n",
      "\n",
      "You can run this code in your Python environment, and it will output the result of each LCM calculation based on the test cases provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A function that computes the lowest common multiples of two integers, and a function that runs 5 test cases of the lowest common multiple function\"\n",
    "run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3cde65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcm(15, 20) = 60\n",
      "lcm(9, 28) = 252\n",
      "lcm(5, 0) = 0\n",
      "lcm(0, 10) = 0\n",
      "lcm(12, 15) = 60\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def lcm(a, b):\n",
    "    \"\"\"Calculate the least common multiple of two integers a and b.\"\"\"\n",
    "    if a == 0 or b == 0:\n",
    "        return 0  # LCM of zero with any number is defined as zero\n",
    "    \n",
    "    return abs(a * b) // math.gcd(a, b)\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Run a set of test cases for the lcm function.\"\"\"\n",
    "    test_cases = [\n",
    "        (15, 20),  # Expected LCM: 60\n",
    "        (9, 28),   # Expected LCM: 252\n",
    "        (5, 0),    # Expected LCM: 0 (with zero)\n",
    "        (0, 10),   # Expected LCM: 0 (with zero)\n",
    "        (12, 15)   # Expected LCM: 60\n",
    "    ]\n",
    "    \n",
    "    for a, b in test_cases:\n",
    "        print(f\"lcm({a}, {b}) = {lcm(a, b)}\")\n",
    "\n",
    "# Run the tests\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6ed2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "Selv om jeg ikke kan fange essensen til Herman Wildenvey perfekt, kan jeg prøve å skrive et dikt inspirert av hans stil. Her er et dikt på norsk:\n",
      "\n",
      "---\n",
      "\n",
      "**Ved Kysten**\n",
      "\n",
      "Under himmelens dype blå,  \n",
      "der bølger hvisker gamle sår,  \n",
      "står jeg alene, mens vinden rår,  \n",
      "og minner svinner som skum av år.\n",
      "\n",
      "Det er kveld, og solen synker,  \n",
      "skygger danser der fjellene blinker,  \n",
      "et hjerte fylt av drømmer og lengsel,  \n",
      "i horisonten, en lysning, en sengsel.\n",
      "\n",
      "Månen vokter sitt stjernespeil,  \n",
      "hvor natten skaper sitt stille seil,  \n",
      "i det fjerne, en melodi så kjær,  \n",
      "som hvisker håp i den myke vær.\n",
      "\n",
      "Å, havets sang i mitt indre bor,  \n",
      "en historie om lengsel, om tapte kor,  \n",
      "men i hver bølges bløte klem,  \n",
      "finner jeg styrke til å starte igjen.\n",
      "\n",
      "Så la meg stå her, i lyset fra stjernene,  \n",
      "med sjelen fri, i naturens garnene,  \n",
      "for i hver bølge, i hver bris som suser,  \n",
      "lever min drøm, som aldri vil fusere.\n",
      "\n",
      "--- \n",
      "\n",
      "Håper dette diktet fanger noe av Wildenveys ånd!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poet = \"Herman Wildenvvey\"\n",
    "prompt = f\"Write a poem in the style of {poet} in Norwegian\"\n",
    "run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87aaf159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hvordan påvirker diabetes insulinproduksjonen?', 'Hvilke matvarer bør diabetikere unngå?', 'Hvordan fungerer insulinpumper?', 'Hvilke øvelser er trygge for diabetikere?', 'Hvordan takle depresjon som følge av diabetes?']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Temabasert ordliste\n",
    "temaer = {\n",
    "    \"sykdomsmekanismer\": [\"Hva er diabetes?\", \"Hvordan påvirker diabetes insulinproduksjonen?\"],\n",
    "    \"kostholdsråd\": [\"Hvilke matvarer bør diabetikere unngå?\", \"Hvordan balansere karbohydrater?\"],\n",
    "    \"medisinering\": [\"Hvilke medisiner brukes vanligvis til å behandle type 2 diabetes?\", \"Hvordan fungerer insulinpumper?\"],\n",
    "    \"livsstil\": [\"Hvilke øvelser er trygge for diabetikere?\", \"Hvordan kan stress påvirke blodsukkernivået?\"],\n",
    "    \"psykologisk støtte\": [\"Hvordan kan jeg snakke med familien min om min diabetes?\", \"Hvordan takle depresjon som følge av diabetes?\"]\n",
    "}\n",
    "\n",
    "# Spørsmålsgenerator\n",
    "def generer_spørsmål(tema):\n",
    "    spørsmål = random.choice(temaer[tema])\n",
    "    return spørsmål\n",
    "\n",
    "# Generere et sett med spørsmål\n",
    "def generer_spørsmålsett():\n",
    "    spørsmålsett = []\n",
    "    for tema in temaer.keys():\n",
    "        spørsmålsett.append(generer_spørsmål(tema))\n",
    "    return spørsmålsett\n",
    "\n",
    "# Eksempel på genererte spørsmål\n",
    "print(generer_spørsmålsett())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0bf3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_liste = generer_spørsmålsett()\n",
    "len(spm_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6e0a020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spm 0: Hva er diabetes?\n",
      "LLM Response:\n",
      "Svar på Spm 0: Diabetes er en kronisk sykdom som oppstår når kroppen ikke klarer å produsere tilstrekkelig insulin, eller når kroppen ikke kan bruke insulin effektivt. Insulin er et hormon som regulerer blodsukkernivået. Det finnes hovedsakelig to typer diabetes: type 1, som vanligvis utvikles i barndommen eller ung voksen alder og krever insulintilførsel, og type 2, som oftere utvikles hos voksne og ofte kan kontrolleres med kosthold, trening og medisiner. Ubehandlet diabetes kan føre til alvorlige helsekomplikasjoner som hjerte- og karsykdommer, nyresykdom, nerveproblemer og synsforstyrrelser. Det er viktig å ha god kontroll over blodsukkeret for å forebygge disse komplikasjonene. Regelmessig oppfølging hos helsepersonell og en sunn livsstil er avgjørende for personer med diabetes.\n",
      "\n",
      "Spm 1: Hvilke matvarer bør diabetikere unngå?\n",
      "LLM Response:\n",
      "Svar på Spm 1: Diabetikere bør unngå matvarer med høyt innhold av sukker og raske karbohydrater, som sukkersøte snacks, brus og bakevarer laget med hvitt mel. Bearbeidede matvarer og hurtigmat bør også begrenses, da de ofte inneholder usunne fettstoffer og tilsatt sukker. Dessuten er det lurt å unngå mat med høyt glykemisk indeks, som hvit ris, potetmos og visse frokostblandinger. Rødt kjøtt og bearbeidede kjøttprodukter kan være mindre gunstige, så det anbefales å velge magre proteinkilder som fisk, kylling og belgfrukter. Endelig bør man være forsiktig med alkohol, da det kan påvirke blodsukkernivået. Fokuser på helfrokost, grønnsaker og fullkornsprodukter for bedre blodsukkerkontroll.\n",
      "\n",
      "Spm 2: Hvordan fungerer insulinpumper?\n",
      "LLM Response:\n",
      "Svar på Spm 2: Insulinpumper er en enhet som leverer kontinuerlig insulin til personer med diabetes for å regulere blodsukkernivået. Pumpen er festet til kroppen og har en liten kateter som plasseres under huden, vanligvis på magen. Den bruker en liten motor til å gi insulin i små, nøyaktige doser, enten kontinuerlig (basaldose) eller ved behov (bolusdose) når man spiser. Brukeren kan programmere pumpen til å tilpasse insulindosene etter aktivitetsnivå og kosthold, noe som gir en mer fleksibel livsstil. Insulinpumpen krever regelmessig overvåking av blodsukkernivåer og justeringer av innstillinger for å opprettholde god glykemisk kontroll. Den kan bidra til å redusere risikoen for både høyt og lavt blodsukker, noe som er viktig for å forebygge komplikasjoner relatert til diabetes.\n",
      "\n",
      "Spm 3: Hvordan kan stress påvirke blodsukkernivået?\n",
      "LLM Response:\n",
      "Svar på Spm 3: Stress kan ha en betydelig innvirkning på blodsukkernivået. Når kroppen opplever stress, aktiveres det sympatiske nervesystemet, noe som fører til produksjon av stresshormoner som adrenalin og kortisol. Disse hormonene stimulerer leveren til å frigjøre glukose i blodet for å gi rask energi, noe som kan føre til høye blodsukkernivåer. Langvarig stress kan føre til kronisk forhøyede glukosenivåer, noe som kan øke risikoen for insulinresistens og type 2-diabetes. I tillegg kan stress påvirke kostholdet og livsstilen, som ofte fører til usunne matvalg og mindre fysisk aktivitet, noe som ytterligere kan forverre blodsukkerkontrollen. Det er derfor viktig å håndtere stress på en sunn måte for å opprettholde stabile blodsukkernivåer.\n",
      "\n",
      "Spm 4: Hvordan takle depresjon som følge av diabetes?\n",
      "LLM Response:\n",
      "Svar på Spm 4: Å takle depresjon som følge av diabetes krever en helhetlig tilnærming. Først er det viktig å søke profesjonell hjelp, enten gjennom psykolog, lege eller diabetesbehandlere. Utforsk støttegrupper for både diabetes og mental helse, da dette kan gi verdifull støtte og erfaringer fra andre. Regelmessig fysisk aktivitet og et balansert kosthold kan forbedre både fysiske og mentale helse. Prøv mindfulness eller meditasjon for å redusere stress og forbedre livskvalitet. Sett realistiske mål for diabetesbehandling og feire små seire. Sørg for å ha et godt nettverk av familie og venner som kan gi støtte. Vær åpen om følelsene dine, og husk at det er normalt å føle seg overveldet. Behovet for å håndtere både diabetes og psykisk helse er viktig for å forbedre livskvaliteten.\n",
      "\n",
      "CPU times: user 38.9 ms, sys: 91 ms, total: 130 ms\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, spm in enumerate(spm_liste):\n",
    "    print(f'Spm {i}: {spm}')\n",
    "    prompt = f\"{spm}. Svar på norsk. Bruk max 150 ord. Start med 'Svar på Spm {i}'. Ikke bruk avsnitt. -m gpt-4o-mini\"\n",
    "    run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07e973ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spm 0: Hva er diabetes?\n",
      "LLM Response:\n",
      "Svar på Spm 0: Diabetes er en kronisk sykdom som oppstår når kroppen har problemer med å regulere blodsukkernivået. Dette kan skyldes at bukspyttkjertelen ikke produserer nok insulin, et hormon som er nødvendig for å transportere glukose inn i cellene, eller at kroppens celler ikke reagerer normalt på insulin. Det finnes hovedsakelig to typer diabetes: type 1, som ofte oppstår i barndommen eller ungdommen, og type 2, som vanligvis utvikler seg senere i livet og er sterkt knyttet til overvekt og livsstil. Symptomer inkluderer økt tørste, hyppig urinering, tretthet og sår som tar lang tid å gro. Behandling kan innebære livsstilsendringer, medisiner og insulinbehandling, avhengig av type og alvorlighetsgrad. Tidlig diagnose og behandling er viktig for å unngå alvorlige komplikasjoner.\n",
      "\n",
      "Spm 1: Hvilke matvarer bør diabetikere unngå?\n",
      "LLM Response:\n",
      "Svar på Spm 1: Diabetikere bør unngå matvarer med høyt sukkerinnhold, som sukkerholdige drikker, godteri, og bakevarer laget med hvitt mel. Raffinerte karbohydrater, som hvitt brød og pasta, kan også føre til hurtige blodsukkerøkninger. I tillegg bør de begrense inntaket av mettet fett og transfett, som finnes i frityrstekte matvarer og behandlet snacks. Alkohol kan også påvirke blodsukkeret, så moderat inntak er viktig. For verktøy er det lurt å begrense inntaket av høy-glykemisk indekse matvarer som poteter og enkelte frokostblandinger. Fokus på hel mat, fiber, og komplekse karbohydrater er å foretrekke for å opprettholde stabilt blodsukker.\n",
      "\n",
      "Spm 2: Hvordan fungerer insulinpumper?\n",
      "LLM Response:\n",
      "Svar på Spm 2: Insulinpumper er en enhet som gir kontinuerlig tilførsel av insulin til personer med diabetes. Pumpen leverer insulin gjennom en kateter, som settes inn i huden, vanligvis i magen eller låret. Den programmeres til å gi en basaldose insulin hele døgnet, samt ekstra bolusdoser ved måltider for å kontrollere blodsukkernivået. Brukeren kan justere innstillingene via en skjerm, noe som gir større fleksibilitet enn injeksjoner. Insulinpumpen måles kontinuerlig i forbindelse med blodsukkeret, og mange modeller kan kobles til kontinuerlige glukosemålere for automatisk justering. Pumpesystemet forbedrer livskvaliteten ved å redusere stikk og gi mer presis insulinregulering. Det er viktig å følge opp med jevnlige målinger og tilpasninger for å oppnå optimal blodsukkerkontroll.\n",
      "\n",
      "Spm 3: Hvordan kan stress påvirke blodsukkernivået?\n",
      "LLM Response:\n",
      "Svar på Spm 3: Stress kan påvirke blodsukkernivået på flere måter. Når kroppen opplever stress, aktiveres det sympatiske nervesystemet, som kan føre til frigjøring av stresshormoner som adrenalin og kortisol. Disse hormonene fremmer omdannelsen av glykogen til glukose i leveren, noe som øker blodsukkernivået for å gi rask energi til kroppen. Langvarig stress kan imidlertid resultere i kronisk forhøyede blodsukkernivåer, hvilket kan være problematisk, spesielt for personer med diabetes. Stress kan også påvirke livsstilsvalg og spisevaner, noe som ytterligere kan forverre blodsukkerreguleringen. Samlet sett kan stress være en betydelig faktor i blodsukkerbalansen, og det er viktig å håndtere stress for å opprettholde et stabilt blodsukkernivå.\n",
      "\n",
      "Spm 4: Hvordan takle depresjon som følge av diabetes?\n",
      "LLM Response:\n",
      "Svar på Spm 4: Å takle depresjon som følge av diabetes kan være utfordrende, men det finnes strategier som kan hjelpe. Det er viktig å søke profesjonell hjelp, som terapi eller rådgivning, for å få verktøy til å håndtere følelsene. Oppretthold en sunn livsstil med et balansert kosthold og regelmessig mosjon, da dette kan forbedre både fysisk og psykisk helse. Vei viktigheten av støtte fra familie og venner; del følelser og erfaringer med dem. Sett realistiske mål for blodsukkerkontroll og ta små skritt mot bedre helse. Mindfulness og avspenningsteknikker kan også redusere angst og depresjon. Husk at det er normalt å oppleve slike følelser, og at det er hjelp å få. Prioriter egenomsorg og vær tålmodig med deg selv i prosessen.\n",
      "\n",
      "CPU times: user 37.8 ms, sys: 88.9 ms, total: 127 ms\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, spm in enumerate(spm_liste):\n",
    "    print(f'Spm {i}: {spm}')\n",
    "    prompt = f\"{spm}. Svar på norsk. Bruk max 150 ord. Start med 'Svar på Spm {i}'. Ikke bruk avsnitt. -m l31i\"\n",
    "    run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16d9195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spm 0: Hva er diabetes?\n",
      "LLM Response:\n",
      "Svar på Spm 0: Diabetes er en kronisk sykdom som oppstår når kroppen ikke klarer å produsere tilstrekkelig insulin, eller når cellene ikke reagerer effektivt på insulin. Dette fører til høye blodsukkernivåer. Det finnes hovedsakelig to typer diabetes: type 1, som ofte oppstår i barndommen eller tidlig voksenliv og skyldes en autoimmun reaksjon som ødelegger insulinproduserende celler i bukspyttkjertelen, og type 2, som oftest utvikler seg hos voksne og er knyttet til livsstilsfaktorer som overvekt og mangel på fysisk aktivitet. Diabetes kan føre til alvorlige helseproblemer som hjerte- og karsykdommer, nyreskader og nerveskader hvis den ikke behandles. Behandling inkluderer kosthold, mosjon, blodsukkerkontroll og medikamenter, avhengig av type og alvorlighetsgrad. Tidlig diagnose og behandling er viktig for å håndtere sykdommen effektivt.\n",
      "\n",
      "Spm 1: Hvordan balansere karbohydrater?\n",
      "LLM Response:\n",
      "Svar på Spm 1: For å balansere karbohydrater, fokuser på kvalitet og mengde. Velg komplekse karbohydrater som fullkorn, frukt og grønnsaker, som gir langsom energi og er rike på fiber. Unngå enkle sukkerarter fra usunne kilder som brus og godteri. Se på porsjonsstørrelser og fordel karbohydratinntaket jevnt gjennom dagen for å unngå blodsukkerstigning. Kombiner karbohydrater med proteiner og sunne fettkilder for å stabilisere blodsukkeret og øke metthetsfølelsen. Lytt til kroppen din og tilpass inntaket etter aktivitetsnivået; eldre og mindre aktive personer trenger ofte færre karbohydrater. Planlegging av måltider og snacks kan også hjelpe med å opprettholde en sunn balanse.\n",
      "\n",
      "Spm 2: Hvilke medisiner brukes vanligvis til å behandle type 2 diabetes?\n",
      "LLM Response:\n",
      "Svar på Spm 2: Vanlige medisiner for behandling av type 2 diabetes inkluderer metformin, som er førstevalget og bidrar til å redusere blodsukkeret ved å øke insulinfølsomheten og hemme glukoseproduksjonen i leveren. Andre medikamenter inkluderer sulfonylurea (som glibenklamid og glipizid), som stimulerer bukspyttkjertelen til å produsere mer insulin, og DPP-4-hemmere (som sitagliptin), som øker insulinutskillelsen og reduserer glukagon. SGLT2-hemmere (som canagliflozin) bidrar til å fjerne sukker gjennom urinen, mens GLP-1-reseptoragonister (som liraglutid) fremmer insulinproduksjon ved høyere blodsukkernivå og gir vekttap. Insulinbehandling kan også være nødvendig i mer avanserte tilfeller. Det er viktig at behandlingen tilpasses individuelt.\n",
      "\n",
      "Spm 3: Hvilke øvelser er trygge for diabetikere?\n",
      "LLM Response:\n",
      "Svar på Spm 3: Diabetikere kan trygt utføre variasjoner av aerobic trening, styrketrening og fleksibilitetsøvelser. Gående, sykling og svømming er gode kardiovaskulære aktiviteter som forbedrer blodsukkerkontrollen. Styrketrening, som inkluderer vekthevning eller kroppen som motstand, kan også være fordelaktig da det bidrar til muskelmasse og stoffskifte. Yoga og stretching øker fleksibilitet og reduserer stress, noe som kan ha positiv innvirkning på blodsukkeret. Det er viktig å konsultere helsepersonell før man begynner med et nytt treningsprogram, og være oppmerksom på blodsukkernivået før, under og etter trening. Å drikke rikelig med vann og ha klare snackalternativer tilgjengelig kan også være lurt for å unngå hypoglykemi. Trening bør tilpasses den enkeltes helsetilstand og fysiske kapasitet.\n",
      "\n",
      "Spm 4: Hvordan kan jeg snakke med familien min om min diabetes?\n",
      "LLM Response:\n",
      "Svar på Spm 4. Det kan være en utfordring å snakke med familien om diabetes, men åpenhet er viktig. Start med å forklare hva diabetes er, og hvordan det påvirker hverdagen din. Del dine erfaringer, og vær ærlig om følelsene dine knyttet til tilstanden. Forklar hvordan de kan støtte deg, enten det gjelder kosthold, trening eller å være bevisste på symptomene. Oppfordre dem til å stille spørsmål, og vær forberedt på at de kanskje ikke vet mye om sykdommen fra før. Del gjerne informasjonskilder om diabetes, slik at de kan forstå bedre. Det kan også være nyttig å involvere en lege eller spesialist som kan gi mer innsikt. Husk at målsettingen er å bygge forståelse og støtte, så vær tålmodig og lyttende i samtalen.\n",
      "\n",
      "CPU times: user 72.4 ms, sys: 79.9 ms, total: 152 ms\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, spm in enumerate(spm_liste):\n",
    "    print(f'Spm {i}: {spm}')\n",
    "    prompt = f\"{spm}. Svar på norsk. Bruk max 150 ord. Start med 'Svar på Spm {i}'. Ikke bruk avsnitt. -m claude-3.5-sonnet\"\n",
    "    run_llm(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25a120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.3",
   "language": "sage",
   "name": "sagemath-10.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
